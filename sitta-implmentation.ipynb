{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10929548,"sourceType":"datasetVersion","datasetId":6795692},{"sourceId":275132,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":235606,"modelId":257292}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r /kaggle/input/sitta_official_replicate/pytorch/default/1  /kaggle/working/","metadata":{"_uuid":"1334c10b-bc05-410c-a67b-9105279c66e9","_cell_guid":"8d42ac52-8e41-40f9-94b0-2520aa9926d1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/1/SITTA-Vidya","metadata":{"_uuid":"9c4c2cec-50a6-4612-b1a6-29a944c9ce36","_cell_guid":"47261d73-e683-41be-896e-573dd8f6ae11","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -l","metadata":{"_uuid":"a01a2a45-e80c-44e1-b0b1-9b3b6ea65e54","_cell_guid":"29d4b66b-d6b1-4947-a8f3-d1e2bf865c3b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch torchvision numpy pyyaml opencv-python matplotlib tqdm","metadata":{"_uuid":"6691d551-52d3-4deb-a156-89e4f2aba2fb","_cell_guid":"7a5f8de6-24d3-4d4c-b36b-92755a81e1fb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch-fidelity lpips","metadata":{"_uuid":"dd880a62-2cbc-4250-82d8-3d69e4ce3128","_cell_guid":"6d7ad5a0-9399-49b6-a479-b178722caeaa","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 2: Dataset Preparation","metadata":{"_uuid":"758ad28a-9aef-4c3f-b200-a76a4edc6b82","_cell_guid":"ad599890-6b00-4dbf-8134-2591de3a8779","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import os\nimport shutil\nimport random\nimport glob\n\n# Define dataset paths\ndataset_path = \"/kaggle/input/plant-pathology-sitta/images\"\noutput_dir = \"/kaggle/working/dataset\"\n\n# Create required directories\nos.makedirs(f\"{output_dir}/leaves/trainA\", exist_ok=True)\nos.makedirs(f\"{output_dir}/leaves/testA\", exist_ok=True)\nos.makedirs(f\"{output_dir}/leaves/trainB\", exist_ok=True)\nos.makedirs(f\"{output_dir}/leaves/testB\", exist_ok=True)\n\n# Get all image files\nall_images = glob.glob(f\"{dataset_path}/*.jpg\")\nrandom.shuffle(all_images)\n\n# Split into 80% train, 20% test\nsplit_idx = int(0.8 * len(all_images))\ntrainA_images = all_images[:split_idx]\ntestA_images = all_images[split_idx:]\n\n# Copy images to trainA/testA\nfor img in trainA_images:\n    shutil.copy(img, f\"{output_dir}/leaves/trainA/\")\n\nfor img in testA_images:\n    shutil.copy(img, f\"{output_dir}/leaves/testA/\")\n\n# Select 200 random images as \"textures\" for trainB\nnum_textures = min(200, len(trainA_images))\ntrainB_images = random.sample(trainA_images, num_textures)\n\n# Move them to trainB (simulating textures)\nfor img in trainB_images:\n    shutil.copy(img, f\"{output_dir}/leaves/trainB/\")\n\n# Move 10% of trainB to testB\ntestB_size = int(0.1 * len(trainB_images))\ntestB_images = trainB_images[:testB_size]\n\nfor img in testB_images:\n    shutil.copy(img, f\"{output_dir}/leaves/testB/\")\n\nprint(\"âœ… Dataset structured successfully!\")","metadata":{"_uuid":"8f659f81-591f-4823-99af-3b5ca8fcb51c","_cell_guid":"953ae93f-d80a-471d-9234-3c8caf194b74","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 3: Resize Images","metadata":{"_uuid":"8df05876-62d1-488b-a8f2-3c5572050fd4","_cell_guid":"e116373a-647d-409e-a27b-7705266f7c68","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from PIL import Image\nimport os\nimport glob\n\n# Define input and output directories\ndataset_dirs = [\"trainA\", \"testA\", \"trainB\", \"testB\"]\nbase_dir = \"/kaggle/working/dataset/leaves\"\n\n# Target size\nTARGET_SIZE = (288, 288)\n\nfor dataset in dataset_dirs:\n    input_folder = os.path.join(base_dir, dataset)\n    resized_folder = os.path.join(base_dir, f\"{dataset}_resized\")\n    os.makedirs(resized_folder, exist_ok=True)\n\n    # Resize all images\n    for img_path in glob.glob(input_folder + \"/*.jpg\"):\n        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB format\n        img = img.resize(TARGET_SIZE, Image.BICUBIC)  # Bicubic interpolation\n        img.save(os.path.join(resized_folder, os.path.basename(img_path)))\n\n    print(f\"âœ… Resized images saved in {resized_folder}\")\n\nprint(\"ðŸ”¥ All images resized successfully!\")","metadata":{"_uuid":"1e3ff369-92a7-46ff-9dcb-d3f936aa9233","_cell_guid":"5ee50f29-fe40-4b6b-a3d2-de8eb00833ca","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 4: Update YAML","metadata":{"_uuid":"1bb5e669-a111-4783-a569-9c7ea16aae75","_cell_guid":"194f32b5-632e-491a-8a1f-10be1cb96da0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import yaml\n\n# Load the YAML file\nyaml_path = \"/kaggle/working/1/SITTA-Vidya/configs/single2single.yaml\"\nwith open(yaml_path, \"r\") as file:\n    config = yaml.safe_load(file)\n\nconfig[\"trainA_dir\"] = \"/kaggle/working/dataset/leaves/trainA_resized\"\nconfig[\"testA_dir\"] = \"/kaggle/working/dataset/leaves/testA_resized\"\nconfig[\"trainB_dir\"] = \"/kaggle/working/dataset/leaves/trainB_resized\"\nconfig[\"testB_dir\"] = \"/kaggle/working/dataset/leaves/testB_resized\"\n\n# Save updated YAML file\nwith open(yaml_path, \"w\") as file:\n    yaml.dump(config, file)\n\nprint(\"âœ… YAML updated successfully!\")","metadata":{"_uuid":"7a698d4f-fc27-4777-a58c-6272303161d9","_cell_guid":"949bdd5f-bc38-4c87-9d9a-a88ffd68395d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 5: SITTA Model Implementation (With PONO)\nThis includes:\n\nPONO Normalization Layer\nSITTA Generator (with and without PONO)\nSITTA Discriminator","metadata":{"_uuid":"a3e6284b-fe53-445c-95e9-6ad9943151e1","_cell_guid":"306fcaf9-3930-4d9d-af5a-28f2d3c39160","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 5.1: Define PONO Normalization","metadata":{"_uuid":"fa02dd62-4e33-4b7d-af29-6214ed22224f","_cell_guid":"d0b7c0f5-f351-42b8-8dd2-f068c6755371","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# Define PONO Normalization Layer\nclass PONO(nn.Module):\n    def __init__(self):\n        super(PONO, self).__init__()\n\n    def forward(self, x):\n        mean = x.mean(dim=[2, 3], keepdim=True)\n        std = x.std(dim=[2, 3], keepdim=True)\n        return (x - mean) / (std + 1e-5), mean, std","metadata":{"_uuid":"a0f73274-f91a-4a15-aadc-8e6da5cb5e9a","_cell_guid":"29e9739e-97cd-431e-a290-e0b2976bcf13","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-05T14:50:33.041756Z","iopub.execute_input":"2025-03-05T14:50:33.042050Z","iopub.status.idle":"2025-03-05T14:50:33.046889Z","shell.execute_reply.started":"2025-03-05T14:50:33.042028Z","shell.execute_reply":"2025-03-05T14:50:33.045846Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  5.2: Define SITTA Generator (With & Without PONO)","metadata":{"_uuid":"7ad9bad1-ed5b-4722-80dd-89dba5d2208f","_cell_guid":"b9ec6703-a490-4205-b63f-d33fd259b74f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Define SITTA Generator with option to enable/disable PONO\nclass SITTA_Generator(nn.Module):\n    def __init__(self, use_pono=False):\n        super(SITTA_Generator, self).__init__()\n        self.use_pono = use_pono\n        self.pono_layer = PONO() if use_pono else None\n\n        # Encoder: Extract features\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, 7, padding=3),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n            nn.ReLU()\n        )\n\n        # Decoder: Generate texture\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 3, 7, padding=3),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        features = self.encoder(x)\n        \n        # Apply PONO if enabled\n        if self.use_pono:\n            features, _, _ = self.pono_layer(features)\n        \n        return self.decoder(features)","metadata":{"_uuid":"6c42868e-fd5a-4d59-a093-11c3cc4cffda","_cell_guid":"95d19001-f5a9-4577-8b35-41a59cef502c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-05T14:51:00.149592Z","iopub.execute_input":"2025-03-05T14:51:00.149884Z","iopub.status.idle":"2025-03-05T14:51:00.156141Z","shell.execute_reply.started":"2025-03-05T14:51:00.149862Z","shell.execute_reply":"2025-03-05T14:51:00.155107Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.3: Define SITTA Discriminator","metadata":{"_uuid":"3868e2c1-091b-48a5-a476-3acc3453de03","_cell_guid":"b1dd49a7-5e3e-47e1-baec-66bc7f0ff6ed","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Define SITTA Discriminator\nclass SITTA_Discriminator(nn.Module):\n    def __init__(self):\n        super(SITTA_Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(256, 1, 4, stride=1, padding=1)\n        )\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"_uuid":"84c5f9e0-2dc1-464c-9d46-5ef3bb96767c","_cell_guid":"a0f2478a-b19a-4150-993d-22faa41c4aff","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-05T14:51:27.165501Z","iopub.execute_input":"2025-03-05T14:51:27.165838Z","iopub.status.idle":"2025-03-05T14:51:27.170902Z","shell.execute_reply.started":"2025-03-05T14:51:27.165815Z","shell.execute_reply":"2025-03-05T14:51:27.169980Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.4: Initialize Models","metadata":{"_uuid":"25d08ed7-ace8-4011-ac6b-1001a83609e3","_cell_guid":"56c59db8-b7b2-4176-ac7e-4fdaad42973a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Initialize models\ngenerator_without_pono = SITTA_Generator(use_pono=False).cuda()\ngenerator_with_pono = SITTA_Generator(use_pono=True).cuda()\ndiscriminator = SITTA_Discriminator().cuda()\n\nprint(\"âœ… Generator (with & without PONO) and Discriminator initialized successfully!\")","metadata":{"_uuid":"ab10a2ad-0074-4ed7-a8af-46096d8f48a3","_cell_guid":"56e8edf1-3abb-4e0a-b8e3-397bb0e31ef6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-05T14:51:53.507894Z","iopub.execute_input":"2025-03-05T14:51:53.508178Z","iopub.status.idle":"2025-03-05T14:51:53.535854Z","shell.execute_reply.started":"2025-03-05T14:51:53.508155Z","shell.execute_reply":"2025-03-05T14:51:53.534946Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 6: Training Function for SITTA (With & Without PONO)\nâœ” Includes:\n\n\n* Adversarial Loss\n* Cycle Consistency Loss\n* Identity Loss\n* Training Function\n* Training Execution for both With & Without PONO","metadata":{"_uuid":"38249b7c-80ab-4003-b5df-bd1994b0170e","_cell_guid":"dc086e0d-0af4-4556-8ef6-8c6f484345b0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 6.1: Define Loss Functions","metadata":{"_uuid":"f11ddce9-225f-41e8-8fa4-a38de36150b6","_cell_guid":"9f93f309-0dbb-4bd6-a5ba-88cdb398d8ef","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.nn.functional as F\n\n# Define loss functions\nadversarial_loss = nn.MSELoss()  # For GAN loss\ncycle_loss = nn.L1Loss()         # Cycle consistency loss\nidentity_loss = nn.L1Loss()      # Identity loss\n\n# Optimizers\noptimizer_G = optim.Adam(generator_with_pono.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n\nprint(\"âœ… Loss functions and optimizers initialized!\")","metadata":{"_uuid":"1b144836-1927-46bd-90f1-fe3f85da89be","_cell_guid":"72e1b96a-6cca-4130-b1a5-d902e825d179","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-05T14:54:39.661779Z","iopub.execute_input":"2025-03-05T14:54:39.662073Z","iopub.status.idle":"2025-03-05T14:54:39.668455Z","shell.execute_reply.started":"2025-03-05T14:54:39.662051Z","shell.execute_reply":"2025-03-05T14:54:39.667516Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.2: Define Training Function","metadata":{"_uuid":"12cdf513-6a2f-44cd-8335-79afa44999b6","_cell_guid":"fc55a799-6407-4e9e-bde2-1b5a79cdbbc1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import time\n\ndef train_sitta(generator, label, epochs=5):\n    \"\"\"\n    Training function for SITTA generator.\n    Runs a simple adversarial loss training loop.\n    \"\"\"\n    print(f\"ðŸš€ Training {label} Generator...\")\n\n    for epoch in range(epochs):\n        start_time = time.time()\n\n        for real_A in trainA_loader:\n            for real_B in trainB_loader:\n                real_A, real_B = real_A.cuda(), real_B.cuda()\n                fake_B = generator(real_A)\n\n                # Compute loss\n                adv_loss = adversarial_loss(discriminator(fake_B), torch.ones_like(discriminator(fake_B)))\n                cyc_loss = cycle_loss(generator(fake_B), real_A)\n                idt_loss = identity_loss(generator(real_B), real_B)\n                gen_loss = adv_loss + 10 * cyc_loss + 5 * idt_loss\n\n                # Optimize Generator\n                optimizer_G.zero_grad()\n                gen_loss.backward()\n                optimizer_G.step()\n\n        end_time = time.time() - start_time\n        print(f\"Epoch [{epoch+1}/{epochs}] - Gen Loss: {gen_loss.item():.4f} - Time: {end_time:.2f}s\")\n\n    print(f\"âœ… Training Complete for {label}!\")","metadata":{"_uuid":"738ab797-077d-4e87-a498-b0b86cf67d91","_cell_guid":"a5bf0fe6-8ffa-4da2-a977-72673f60c547","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-05T14:55:10.444385Z","iopub.execute_input":"2025-03-05T14:55:10.444714Z","iopub.status.idle":"2025-03-05T14:55:10.450678Z","shell.execute_reply.started":"2025-03-05T14:55:10.444685Z","shell.execute_reply":"2025-03-05T14:55:10.449754Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.3: Train Both Models (With & Without PONO)","metadata":{"_uuid":"ae120d58-25f4-4358-bc4b-c5718660f80a","_cell_guid":"6fd37081-0e9a-45b1-accb-0a2e6f60d60c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Train without PONO\ntrain_sitta(generator_without_pono, \"Without PONO\")\n\n# Train with PONO\ntrain_sitta(generator_with_pono, \"With PONO\")\n\nprint(\"âœ… Training completed for both versions!\")","metadata":{"_uuid":"87467d34-a792-4bb0-88ba-fadad05b4ed3","_cell_guid":"28535b93-5cfe-4370-b9e1-adb62d63e600","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-05T14:55:35.705182Z","iopub.execute_input":"2025-03-05T14:55:35.705503Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 7: Evaluation Metrics for SITTA\nâœ” Includes:\n\n* FID (FrÃ©chet Inception Distance)\n* LPIPS (Learned Perceptual Image Patch Similarity)\n* VGG Loss\n* Visualization of Results","metadata":{"_uuid":"ccc09b69-c11d-414b-b31d-27b225513af2","_cell_guid":"45587e18-4f28-4304-ae3e-b7ae826cfc81","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 7.1: Define FID Calculation","metadata":{"_uuid":"5b3832cb-6797-4082-a8b0-6375e7ad391e","_cell_guid":"65fa9483-d809-454e-b36b-ee2b0afb367c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from torch_fidelity import calculate_metrics\n\ndef compute_fid(real_images, generated_images):\n    \"\"\"\n    Compute FID between real and generated images.\n    \"\"\"\n    metrics = calculate_metrics(\n        input1=real_images,\n        input2=generated_images,\n        fid=True,\n        cuda=torch.cuda.is_available()\n    )\n    return metrics[\"frechet_inception_distance\"]","metadata":{"_uuid":"e9acb44d-ade4-4d26-af4e-3814c556faed","_cell_guid":"a5dd7d0a-d478-44f9-aa0f-921d0680f6d8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  7.2: Define LPIPS Calculation","metadata":{"_uuid":"819176b0-7fb5-4aff-9881-ba780763668b","_cell_guid":"d36c3d6b-5813-422d-bfdf-6ee13fb3dab8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import lpips\n\nlpips_model = lpips.LPIPS(net='alex').to(device)\n\ndef compute_lpips(real_images, generated_images):\n    \"\"\"\n    Compute LPIPS score.\n    \"\"\"\n    return lpips_model(real_images, generated_images).mean().item()","metadata":{"_uuid":"6f35de51-e303-4642-930f-d01d51630e2a","_cell_guid":"01f75b61-f30d-4f0b-b317-82b65c69d6bd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.3: Update VGG Loss","metadata":{"_uuid":"778dcc29-81c0-479c-ad3a-88f8f0156fa6","_cell_guid":"ef1446d0-c310-43ab-a855-d55f65b6ee77","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torchvision.models as models\n\nclass VGGLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.vgg = models.vgg19(pretrained=True).features[:16].eval()\n        for param in self.vgg.parameters():\n            param.requires_grad = False\n        self.criterion = nn.L1Loss()\n\n    def forward(self, generated, target):\n        generated_features = self.vgg(generated)\n        target_features = self.vgg(target).detach()\n        return self.criterion(generated_features, target_features)","metadata":{"_uuid":"cf7d636a-1a71-434c-85d3-b8e8394a5864","_cell_guid":"78e863c8-23d6-4ae7-a64b-dccabb4670fb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  7.4: Evaluate Trained Models","metadata":{"_uuid":"0378c4bd-19d4-4a27-996d-e164dd7108bd","_cell_guid":"5b6520d8-6f48-47be-acbf-47a1c0815e89","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Generate images for evaluation\ntest_real_A = next(iter(trainA_loader)).cuda()[:8]  # Get a batch of real images\ntest_fake_B = generator_with_pono(test_real_A).detach()  # Generate textures\n\n# Compute evaluation metrics\nfid_score = compute_fid(test_real_A, test_fake_B)\nlpips_score = compute_lpips(test_real_A, test_fake_B)\n\nprint(f\"ðŸ“Š FID Score: {fid_score:.2f}\")\nprint(f\"ðŸ“Š LPIPS Score: {lpips_score:.3f}\")","metadata":{"_uuid":"58ed826f-9dc1-4a22-8879-ca68a7c02f32","_cell_guid":"d6d0e091-513c-4f4f-9e35-857a3f33a415","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.5: Visualizing Results","metadata":{"_uuid":"3f09ac9c-d5f7-4546-bced-5cb8b293ba3b","_cell_guid":"74830711-bcdc-42bf-ad8a-2c2c433e1ec0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef visualize_results(real_A, fake_B):\n    \"\"\"\n    Displays a side-by-side comparison of real images and their generated textures.\n    \"\"\"\n    real_A = real_A.permute(0, 2, 3, 1).cpu().numpy()\n    fake_B = fake_B.permute(0, 2, 3, 1).cpu().numpy()\n\n    fig, axes = plt.subplots(2, len(real_A), figsize=(12, 5))\n    \n    for i in range(len(real_A)):\n        axes[0, i].imshow(real_A[i])\n        axes[0, i].axis(\"off\")\n        axes[1, i].imshow(fake_B[i])\n        axes[1, i].axis(\"off\")\n\n    axes[0, 0].set_title(\"Original Shape\")\n    axes[1, 0].set_title(\"Generated Texture\")\n    plt.show()\n\n# Display a batch of results\nvisualize_results(test_real_A, test_fake_B)","metadata":{"_uuid":"f61a4c0d-73c6-413a-9d05-b8b57c1dc337","_cell_guid":"6a23b365-896a-40ea-8ec3-a91a46b9d695","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}