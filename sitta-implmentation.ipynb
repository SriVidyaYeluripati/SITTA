{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10929548,"sourceType":"datasetVersion","datasetId":6795692},{"sourceId":275132,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":235606,"modelId":257292}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r /kaggle/input/sitta_official_replicate/pytorch/default/1  /kaggle/working/","metadata":{"_uuid":"1334c10b-bc05-410c-a67b-9105279c66e9","_cell_guid":"8d42ac52-8e41-40f9-94b0-2520aa9926d1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-05T17:27:15.952548Z","iopub.execute_input":"2025-03-05T17:27:15.952899Z","iopub.status.idle":"2025-03-05T17:27:16.152237Z","shell.execute_reply.started":"2025-03-05T17:27:15.952876Z","shell.execute_reply":"2025-03-05T17:27:16.151262Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"%cd /kaggle/working/1/SITTA-Vidya","metadata":{"_uuid":"9c4c2cec-50a6-4612-b1a6-29a944c9ce36","_cell_guid":"47261d73-e683-41be-896e-573dd8f6ae11","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-05T17:27:19.546257Z","iopub.execute_input":"2025-03-05T17:27:19.546555Z","iopub.status.idle":"2025-03-05T17:27:19.553922Z","shell.execute_reply.started":"2025-03-05T17:27:19.546534Z","shell.execute_reply":"2025-03-05T17:27:19.553195Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/1/SITTA-Vidya\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!ls -l","metadata":{"_uuid":"a01a2a45-e80c-44e1-b0b1-9b3b6ea65e54","_cell_guid":"29d4b66b-d6b1-4947-a8f3-d1e2bf865c3b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch torchvision numpy pyyaml opencv-python matplotlib tqdm","metadata":{"_uuid":"6691d551-52d3-4deb-a156-89e4f2aba2fb","_cell_guid":"7a5f8de6-24d3-4d4c-b36b-92755a81e1fb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch-fidelity lpips","metadata":{"_uuid":"dd880a62-2cbc-4250-82d8-3d69e4ce3128","_cell_guid":"6d7ad5a0-9399-49b6-a479-b178722caeaa","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-05T17:27:28.921569Z","iopub.execute_input":"2025-03-05T17:27:28.921867Z","iopub.status.idle":"2025-03-05T17:27:33.876083Z","shell.execute_reply.started":"2025-03-05T17:27:28.921846Z","shell.execute_reply":"2025-03-05T17:27:33.875258Z"}},"outputs":[{"name":"stdout","text":"Collecting torch-fidelity\n  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\nCollecting lpips\n  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (11.0.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (1.13.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (0.20.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-fidelity) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-fidelity) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch-fidelity) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->torch-fidelity) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-fidelity) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-fidelity) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-fidelity) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-fidelity) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-fidelity) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-fidelity) (2024.2.0)\nDownloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\nDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torch-fidelity, lpips\nSuccessfully installed lpips-0.1.4 torch-fidelity-0.3.0\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\ndef setup(rank, world_size):\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n    torch.cuda.set_device(rank)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:21:53.879263Z","iopub.execute_input":"2025-03-05T17:21:53.879680Z","iopub.status.idle":"2025-03-05T17:21:53.883712Z","shell.execute_reply.started":"2025-03-05T17:21:53.879641Z","shell.execute_reply":"2025-03-05T17:21:53.882981Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Step 2: Dataset Preparation","metadata":{"_uuid":"758ad28a-9aef-4c3f-b200-a76a4edc6b82","_cell_guid":"ad599890-6b00-4dbf-8134-2591de3a8779","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import os\nimport shutil\nimport random\nimport glob\n\n# Define dataset paths\ndataset_path = \"/kaggle/input/plant-pathology-sitta/images\"\noutput_dir = \"/kaggle/working/dataset\"\n\n# Create required directories\nos.makedirs(f\"{output_dir}/leaves/trainA\", exist_ok=True)\nos.makedirs(f\"{output_dir}/leaves/testA\", exist_ok=True)\nos.makedirs(f\"{output_dir}/leaves/trainB\", exist_ok=True)\nos.makedirs(f\"{output_dir}/leaves/testB\", exist_ok=True)\n\n# Get all image files\nall_images = glob.glob(f\"{dataset_path}/*.jpg\")\nrandom.shuffle(all_images)\n\n# Split into 80% train, 20% test\nsplit_idx = int(0.8 * len(all_images))\ntrainA_images = all_images[:split_idx]\ntestA_images = all_images[split_idx:]\n\n# Copy images to trainA/testA\nfor img in trainA_images:\n    shutil.copy(img, f\"{output_dir}/leaves/trainA/\")\n\nfor img in testA_images:\n    shutil.copy(img, f\"{output_dir}/leaves/testA/\")\n\n# Select 200 random images as \"textures\" for trainB\nnum_textures = min(200, len(trainA_images))\ntrainB_images = random.sample(trainA_images, num_textures)\n\n# Move them to trainB (simulating textures)\nfor img in trainB_images:\n    shutil.copy(img, f\"{output_dir}/leaves/trainB/\")\n\n# Move 10% of trainB to testB\ntestB_size = int(0.1 * len(trainB_images))\ntestB_images = trainB_images[:testB_size]\n\nfor img in testB_images:\n    shutil.copy(img, f\"{output_dir}/leaves/testB/\")\n\nprint(\"‚úÖ Dataset structured successfully!\")","metadata":{"_uuid":"8f659f81-591f-4823-99af-3b5ca8fcb51c","_cell_guid":"953ae93f-d80a-471d-9234-3c8caf194b74","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-05T17:21:55.935945Z","iopub.execute_input":"2025-03-05T17:21:55.936226Z","iopub.status.idle":"2025-03-05T17:22:33.446471Z","shell.execute_reply.started":"2025-03-05T17:21:55.936205Z","shell.execute_reply":"2025-03-05T17:22:33.445741Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Dataset structured successfully!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Step 3: Resize Images","metadata":{"_uuid":"8df05876-62d1-488b-a8f2-3c5572050fd4","_cell_guid":"e116373a-647d-409e-a27b-7705266f7c68","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from PIL import Image\nimport os\nimport glob\n\n# Define input and output directories\ndataset_dirs = [\"trainA\", \"testA\", \"trainB\", \"testB\"]\nbase_dir = \"/kaggle/working/dataset/leaves\"\n\n# Target size\nTARGET_SIZE = (288, 288)\n\nfor dataset in dataset_dirs:\n    input_folder = os.path.join(base_dir, dataset)\n    resized_folder = os.path.join(base_dir, f\"{dataset}_resized\")\n    os.makedirs(resized_folder, exist_ok=True)\n\n    # Resize all images\n    for img_path in glob.glob(input_folder + \"/*.jpg\"):\n        img = Image.open(img_path).convert(\"RGB\")  # Convert to RGB format\n        img = img.resize(TARGET_SIZE, Image.BICUBIC)  # Bicubic interpolation\n        img.save(os.path.join(resized_folder, os.path.basename(img_path)))\n\n    print(f\"‚úÖ Resized images saved in {resized_folder}\")\n\nprint(\"üî• All images resized successfully!\")","metadata":{"_uuid":"1e3ff369-92a7-46ff-9dcb-d3f936aa9233","_cell_guid":"5ee50f29-fe40-4b6b-a3d2-de8eb00833ca","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-05T17:22:33.447367Z","iopub.execute_input":"2025-03-05T17:22:33.447661Z","iopub.status.idle":"2025-03-05T17:25:37.902760Z","shell.execute_reply.started":"2025-03-05T17:22:33.447628Z","shell.execute_reply":"2025-03-05T17:25:37.902020Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Resized images saved in /kaggle/working/dataset/leaves/trainA_resized\n‚úÖ Resized images saved in /kaggle/working/dataset/leaves/testA_resized\n‚úÖ Resized images saved in /kaggle/working/dataset/leaves/trainB_resized\n‚úÖ Resized images saved in /kaggle/working/dataset/leaves/testB_resized\nüî• All images resized successfully!\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Step 4: Update YAML","metadata":{"_uuid":"1bb5e669-a111-4783-a569-9c7ea16aae75","_cell_guid":"194f32b5-632e-491a-8a1f-10be1cb96da0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import yaml\n\n# Load the YAML file\nyaml_path = \"/kaggle/working/1/SITTA-Vidya/configs/single2single.yaml\"\nwith open(yaml_path, \"r\") as file:\n    config = yaml.safe_load(file)\n\nconfig[\"trainA_dir\"] = \"/kaggle/working/dataset/leaves/trainA_resized\"\nconfig[\"testA_dir\"] = \"/kaggle/working/dataset/leaves/testA_resized\"\nconfig[\"trainB_dir\"] = \"/kaggle/working/dataset/leaves/trainB_resized\"\nconfig[\"testB_dir\"] = \"/kaggle/working/dataset/leaves/testB_resized\"\n\n# Save updated YAML file\nwith open(yaml_path, \"w\") as file:\n    yaml.dump(config, file)\n\nprint(\"‚úÖ YAML updated successfully!\")","metadata":{"_uuid":"7a698d4f-fc27-4777-a58c-6272303161d9","_cell_guid":"949bdd5f-bc38-4c87-9d9a-a88ffd68395d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-05T17:27:38.590920Z","iopub.execute_input":"2025-03-05T17:27:38.591293Z","iopub.status.idle":"2025-03-05T17:27:38.608536Z","shell.execute_reply.started":"2025-03-05T17:27:38.591264Z","shell.execute_reply":"2025-03-05T17:27:38.607673Z"}},"outputs":[{"name":"stdout","text":"‚úÖ YAML updated successfully!\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## DataLoaders","metadata":{}},{"cell_type":"code","source":"import os\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\n# Define dataset paths\ndataset_path = \"/kaggle/working/dataset/leaves\"\n\n# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((288, 288)),  \n    transforms.ToTensor(),          \n])\n\n# Custom Dataset Class\nclass CustomImageDataset(Dataset):\n    def __init__(self, image_dir, transform=None):\n        self.image_dir = image_dir\n        self.image_paths = [os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith(('.jpg', '.png'))]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert(\"RGB\")  # Convert to RGB format\n        if self.transform:\n            image = self.transform(image)\n        return image  # Return only the image (No label since it's unsupervised)\n\n# Load datasets using CustomImageDataset\ntrainA_dataset = CustomImageDataset(image_dir=f\"{dataset_path}/trainA_resized\", transform=transform)\ntrainB_dataset = CustomImageDataset(image_dir=f\"{dataset_path}/trainB_resized\", transform=transform)\n\n# Create DataLoaders\ntrainA_loader = DataLoader(trainA_dataset, batch_size=8, shuffle=True)\ntrainB_loader = DataLoader(trainB_dataset, batch_size=8, shuffle=True)\n\nprint(f\"‚úÖ Loaded {len(trainA_dataset)} images in TrainA and {len(trainB_dataset)} images in TrainB\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T17:34:51.419045Z","iopub.execute_input":"2025-03-05T17:34:51.419495Z","iopub.status.idle":"2025-03-05T17:34:52.057368Z","shell.execute_reply.started":"2025-03-05T17:34:51.419453Z","shell.execute_reply":"2025-03-05T17:34:52.056577Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loaded 2913 images in TrainA and 200 images in TrainB\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# Step 5: SITTA Model Implementation (With PONO)\nThis includes:\n\nPONO Normalization Layer\nSITTA Generator (with and without PONO)\nSITTA Discriminator","metadata":{"_uuid":"a3e6284b-fe53-445c-95e9-6ad9943151e1","_cell_guid":"306fcaf9-3930-4d9d-af5a-28f2d3c39160","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 5.1: Define PONO Normalization","metadata":{"_uuid":"fa02dd62-4e33-4b7d-af29-6214ed22224f","_cell_guid":"d0b7c0f5-f351-42b8-8dd2-f068c6755371","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# Define PONO Normalization Layer\nclass PONO(nn.Module):\n    def __init__(self):\n        super(PONO, self).__init__()\n\n    def forward(self, x):\n        mean = x.mean(dim=[2, 3], keepdim=True)\n        std = x.std(dim=[2, 3], keepdim=True)\n        return (x - mean) / (std + 1e-5), mean, std","metadata":{"_uuid":"a0f73274-f91a-4a15-aadc-8e6da5cb5e9a","_cell_guid":"29e9739e-97cd-431e-a290-e0b2976bcf13","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-05T17:37:32.379233Z","iopub.execute_input":"2025-03-05T17:37:32.379502Z","iopub.status.idle":"2025-03-05T17:37:32.384219Z","shell.execute_reply.started":"2025-03-05T17:37:32.379482Z","shell.execute_reply":"2025-03-05T17:37:32.383301Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"##  5.2: Define SITTA Generator (With & Without PONO)","metadata":{"_uuid":"7ad9bad1-ed5b-4722-80dd-89dba5d2208f","_cell_guid":"b9ec6703-a490-4205-b63f-d33fd259b74f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Define SITTA Generator with option to enable/disable PONO\nclass SITTA_Generator(nn.Module):\n    def __init__(self, use_pono=False):\n        super(SITTA_Generator, self).__init__()\n        self.use_pono = use_pono\n        self.pono_layer = PONO() if use_pono else None\n\n        # Encoder: Extract features\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, 7, padding=3),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n            nn.ReLU()\n        )\n\n        # Decoder: Generate texture\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 3, 7, padding=3),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        features = self.encoder(x)\n        \n        # Apply PONO if enabled\n        if self.use_pono:\n            features, _, _ = self.pono_layer(features)\n        \n        return self.decoder(features)","metadata":{"_uuid":"6c42868e-fd5a-4d59-a093-11c3cc4cffda","_cell_guid":"95d19001-f5a9-4577-8b35-41a59cef502c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-05T17:37:33.408273Z","iopub.execute_input":"2025-03-05T17:37:33.408682Z","iopub.status.idle":"2025-03-05T17:37:33.417993Z","shell.execute_reply.started":"2025-03-05T17:37:33.408647Z","shell.execute_reply":"2025-03-05T17:37:33.417064Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"## 5.3: Define SITTA Discriminator","metadata":{"_uuid":"3868e2c1-091b-48a5-a476-3acc3453de03","_cell_guid":"b1dd49a7-5e3e-47e1-baec-66bc7f0ff6ed","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Define SITTA Discriminator\nclass SITTA_Discriminator(nn.Module):\n    def __init__(self):\n        super(SITTA_Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(256, 1, 4, stride=1, padding=1)\n        )\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"_uuid":"84c5f9e0-2dc1-464c-9d46-5ef3bb96767c","_cell_guid":"a0f2478a-b19a-4150-993d-22faa41c4aff","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-05T17:37:37.154505Z","iopub.execute_input":"2025-03-05T17:37:37.154808Z","iopub.status.idle":"2025-03-05T17:37:37.159981Z","shell.execute_reply.started":"2025-03-05T17:37:37.154786Z","shell.execute_reply":"2025-03-05T17:37:37.159058Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 5.4: Initialize Models","metadata":{"_uuid":"25d08ed7-ace8-4011-ac6b-1001a83609e3","_cell_guid":"56c59db8-b7b2-4176-ac7e-4fdaad42973a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Initialize models\ngenerator_without_pono = SITTA_Generator(use_pono=False).cuda()\ngenerator_with_pono = SITTA_Generator(use_pono=True).cuda()\ndiscriminator = SITTA_Discriminator().cuda()\n\nprint(\"‚úÖ Generator (with & without PONO) and Discriminator initialized successfully!\")","metadata":{"_uuid":"ab10a2ad-0074-4ed7-a8af-46096d8f48a3","_cell_guid":"56e8edf1-3abb-4e0a-b8e3-397bb0e31ef6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-05T17:37:40.289359Z","iopub.execute_input":"2025-03-05T17:37:40.289678Z","iopub.status.idle":"2025-03-05T17:37:40.315235Z","shell.execute_reply.started":"2025-03-05T17:37:40.289654Z","shell.execute_reply":"2025-03-05T17:37:40.314567Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"‚úÖ Generator (with & without PONO) and Discriminator initialized successfully!\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"# Step 6: Training Function for SITTA (With & Without PONO)\n‚úî Includes:\n\n\n* Adversarial Loss\n* Cycle Consistency Loss\n* Identity Loss\n* Training Function\n* Training Execution for both With & Without PONO","metadata":{"_uuid":"38249b7c-80ab-4003-b5df-bd1994b0170e","_cell_guid":"dc086e0d-0af4-4556-8ef6-8c6f484345b0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 6.1: Define Loss Functions","metadata":{"_uuid":"f11ddce9-225f-41e8-8fa4-a38de36150b6","_cell_guid":"9f93f309-0dbb-4bd6-a5ba-88cdb398d8ef","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.nn.functional as F\n\n# Define loss functions\nadversarial_loss = nn.MSELoss()  # For GAN loss\ncycle_loss = nn.L1Loss()         # Cycle consistency loss\nidentity_loss = nn.L1Loss()      # Identity loss\n\n# Optimizers\noptimizer_G = optim.Adam(generator_with_pono.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n\nprint(\"‚úÖ Loss functions and optimizers initialized!\")","metadata":{"_uuid":"1b144836-1927-46bd-90f1-fe3f85da89be","_cell_guid":"72e1b96a-6cca-4130-b1a5-d902e825d179","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-05T17:37:46.028398Z","iopub.execute_input":"2025-03-05T17:37:46.028695Z","iopub.status.idle":"2025-03-05T17:37:46.034521Z","shell.execute_reply.started":"2025-03-05T17:37:46.028672Z","shell.execute_reply":"2025-03-05T17:37:46.033700Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"‚úÖ Loss functions and optimizers initialized!\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## 6.2: Define Training Function","metadata":{"_uuid":"12cdf513-6a2f-44cd-8335-79afa44999b6","_cell_guid":"fc55a799-6407-4e9e-bde2-1b5a79cdbbc1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import time\n\ndef train_sitta(generator, label, trainA_loader, trainB_loader, epochs=5):\n    \"\"\"\n    Training function for SITTA generator.\n    Runs a simple adversarial loss training loop.\n    \"\"\"\n    print(f\"üöÄ Training {label} Generator...\")\n\n    for epoch in range(epochs):\n        start_time = time.time()\n\n        for real_A in trainA_loader:\n            for real_B in trainB_loader:\n                real_A, real_B = real_A.cuda(), real_B.cuda()\n                fake_B = generator(real_A)\n\n                # Compute loss\n                adv_loss = adversarial_loss(discriminator(fake_B), torch.ones_like(discriminator(fake_B)))\n                cyc_loss = cycle_loss(generator(fake_B), real_A)\n                idt_loss = identity_loss(generator(real_B), real_B)\n                gen_loss = adv_loss + 10 * cyc_loss + 5 * idt_loss\n\n                # Optimize Generator\n                optimizer_G.zero_grad()\n                gen_loss.backward()\n                optimizer_G.step()\n\n        end_time = time.time() - start_time\n        print(f\"Epoch [{epoch+1}/{epochs}] - Gen Loss: {gen_loss.item():.4f} - Time: {end_time:.2f}s\")\n\n    print(f\"‚úÖ Training Complete for {label}!\")","metadata":{"_uuid":"738ab797-077d-4e87-a498-b0b86cf67d91","_cell_guid":"a5bf0fe6-8ffa-4da2-a977-72673f60c547","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-05T17:38:44.627987Z","iopub.execute_input":"2025-03-05T17:38:44.628326Z","iopub.status.idle":"2025-03-05T17:38:44.634497Z","shell.execute_reply.started":"2025-03-05T17:38:44.628300Z","shell.execute_reply":"2025-03-05T17:38:44.633546Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"## 6.3: Train Both Models (With & Without PONO)","metadata":{"_uuid":"ae120d58-25f4-4358-bc4b-c5718660f80a","_cell_guid":"6fd37081-0e9a-45b1-accb-0a2e6f60d60c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Train without PONO\ngenerator_without_pono = SITTA_Generator(use_pono=False).cuda()\ntrain_sitta(generator_without_pono, \"Without PONO\", trainA_loader, trainB_loader)\n\n# Train with PONO\ngenerator_with_pono = SITTA_Generator(use_pono=True).cuda()\ntrain_sitta(generator_with_pono, \"With PONO\", trainA_loader, trainB_loader)\n\nprint(\"‚úÖ Training completed for both versions!\")\n","metadata":{"_uuid":"87467d34-a792-4bb0-88ba-fadad05b4ed3","_cell_guid":"28535b93-5cfe-4370-b9e1-adb62d63e600","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-05T17:38:46.999101Z","iopub.execute_input":"2025-03-05T17:38:46.999414Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"üöÄ Training Without PONO Generator...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Step 7: Evaluation Metrics for SITTA\n‚úî Includes:\n\n* FID (Fr√©chet Inception Distance)\n* LPIPS (Learned Perceptual Image Patch Similarity)\n* VGG Loss\n* Visualization of Results","metadata":{"_uuid":"ccc09b69-c11d-414b-b31d-27b225513af2","_cell_guid":"45587e18-4f28-4304-ae3e-b7ae826cfc81","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 7.1: Define FID Calculation","metadata":{"_uuid":"5b3832cb-6797-4082-a8b0-6375e7ad391e","_cell_guid":"65fa9483-d809-454e-b36b-ee2b0afb367c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from torch_fidelity import calculate_metrics\n\ndef compute_fid(real_images, generated_images):\n    \"\"\"\n    Compute FID between real and generated images.\n    \"\"\"\n    metrics = calculate_metrics(\n        input1=real_images,\n        input2=generated_images,\n        fid=True,\n        cuda=torch.cuda.is_available()\n    )\n    return metrics[\"frechet_inception_distance\"]","metadata":{"_uuid":"e9acb44d-ade4-4d26-af4e-3814c556faed","_cell_guid":"a5dd7d0a-d478-44f9-aa0f-921d0680f6d8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  7.2: Define LPIPS Calculation","metadata":{"_uuid":"819176b0-7fb5-4aff-9881-ba780763668b","_cell_guid":"d36c3d6b-5813-422d-bfdf-6ee13fb3dab8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import lpips\n\nlpips_model = lpips.LPIPS(net='alex').to(device)\n\ndef compute_lpips(real_images, generated_images):\n    \"\"\"\n    Compute LPIPS score.\n    \"\"\"\n    return lpips_model(real_images, generated_images).mean().item()","metadata":{"_uuid":"6f35de51-e303-4642-930f-d01d51630e2a","_cell_guid":"01f75b61-f30d-4f0b-b317-82b65c69d6bd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.3: Update VGG Loss","metadata":{"_uuid":"778dcc29-81c0-479c-ad3a-88f8f0156fa6","_cell_guid":"ef1446d0-c310-43ab-a855-d55f65b6ee77","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import torchvision.models as models\n\nclass VGGLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.vgg = models.vgg19(pretrained=True).features[:16].eval()\n        for param in self.vgg.parameters():\n            param.requires_grad = False\n        self.criterion = nn.L1Loss()\n\n    def forward(self, generated, target):\n        generated_features = self.vgg(generated)\n        target_features = self.vgg(target).detach()\n        return self.criterion(generated_features, target_features)","metadata":{"_uuid":"cf7d636a-1a71-434c-85d3-b8e8394a5864","_cell_guid":"78e863c8-23d6-4ae7-a64b-dccabb4670fb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  7.4: Evaluate Trained Models","metadata":{"_uuid":"0378c4bd-19d4-4a27-996d-e164dd7108bd","_cell_guid":"5b6520d8-6f48-47be-acbf-47a1c0815e89","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"print(\"üîç Evaluating SITTA With & Without PONO...\")\n\n# Compute evaluation metrics\nfid_without_pono = compute_fid(real_B, generator_without_pono(real_A))\nlpips_without_pono = compute_lpips(real_B, generator_without_pono(real_A))\n\nfid_with_pono = compute_fid(real_B, generator_with_pono(real_A))\nlpips_with_pono = compute_lpips(real_B, generator_with_pono(real_A))\n\nprint(f\"üìä FID Score Without PONO: {fid_without_pono:.2f}\")\nprint(f\"üìä LPIPS Score Without PONO: {lpips_without_pono:.3f}\")\nprint(f\"üìä FID Score With PONO: {fid_with_pono:.2f}\")\nprint(f\"üìä LPIPS Score With PONO: {lpips_with_pono:.3f}\")\n","metadata":{"_uuid":"58ed826f-9dc1-4a22-8879-ca68a7c02f32","_cell_guid":"d6d0e091-513c-4f4f-9e35-857a3f33a415","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.5: Visualizing Results","metadata":{"_uuid":"3f09ac9c-d5f7-4546-bced-5cb8b293ba3b","_cell_guid":"74830711-bcdc-42bf-ad8a-2c2c433e1ec0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef visualize_results(real_A, fake_B):\n    \"\"\"\n    Displays a side-by-side comparison of real images and their generated textures.\n    \"\"\"\n    real_A = real_A.permute(0, 2, 3, 1).cpu().numpy()\n    fake_B = fake_B.permute(0, 2, 3, 1).cpu().numpy()\n\n    fig, axes = plt.subplots(2, len(real_A), figsize=(12, 5))\n    \n    for i in range(len(real_A)):\n        axes[0, i].imshow(real_A[i])\n        axes[0, i].axis(\"off\")\n        axes[1, i].imshow(fake_B[i])\n        axes[1, i].axis(\"off\")\n\n    axes[0, 0].set_title(\"Original Shape\")\n    axes[1, 0].set_title(\"Generated Texture\")\n    plt.show()\n\n# Display a batch of results\nvisualize_results(test_real_A, test_fake_B)","metadata":{"_uuid":"f61a4c0d-73c6-413a-9d05-b8b57c1dc337","_cell_guid":"6a23b365-896a-40ea-8ec3-a91a46b9d695","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot FID & LPIPS for PONO vs No PONO\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\naxes[0].bar([\"Without PONO\", \"With PONO\"], [fid_without_pono, fid_with_pono], color=['red', 'green'])\naxes[0].set_title(\"FID Score Comparison\")\naxes[0].set_ylabel(\"FID Score\")\n\naxes[1].bar([\"Without PONO\", \"With PONO\"], [lpips_without_pono, lpips_with_pono], color=['red', 'green'])\naxes[1].set_title(\"LPIPS Score Comparison\")\naxes[1].set_ylabel(\"LPIPS Score\")\n\nplt.show()\nprint(\"‚úÖ PONO Ablation Study Completed!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 8: Compare SITTA With PONO vs Without PONO\nüöÄ This step will compare the model‚Äôs performance when using PONO vs not using PONO.\n‚úî We will train two versions of the model and evaluate them.","metadata":{}},{"cell_type":"markdown","source":"## 8.1: Define Training Function for PONO Comparison","metadata":{}},{"cell_type":"code","source":"def train_sitta(generator, label):\n    \"\"\"\n    Trains the SITTA model and evaluates performance with and without PONO.\n    \"\"\"\n    epochs = 5\n    for epoch in range(epochs):\n        for real_A in trainA_loader:\n            for real_B in trainB_loader:\n                real_A, real_B = real_A.cuda(), real_B.cuda()\n                fake_B = generator(real_A)\n\n                # Compute loss\n                gen_loss = adversarial_loss(discriminator(fake_B), torch.ones_like(discriminator(fake_B)))\n\n                # Optimize Generator\n                optimizer_G.zero_grad()\n                gen_loss.backward()\n                optimizer_G.step()\n\n        print(f\"‚úÖ Epoch [{epoch+1}/{epochs}] - {label} Training Done!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8.2: Train and Evaluate PONO vs Non-PONO","metadata":{}},{"cell_type":"code","source":"# Train without PONO\ngenerator_without_pono = SITTA_Generator(use_pono=False).cuda()\ntrain_sitta(generator_without_pono, \"Without PONO\")\n\n# Train with PONO\ngenerator_with_pono = SITTA_Generator(use_pono=True).cuda()\ntrain_sitta(generator_with_pono, \"With PONO\")\n\nprint(\"‚úÖ Training completed for both versions!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 9: Save and Export the Final Trained Model","metadata":{}},{"cell_type":"markdown","source":"## 9.1: Save Trained Models","metadata":{}},{"cell_type":"code","source":"# Create directory for saved models\nos.makedirs(\"/kaggle/working/sitta_models\", exist_ok=True)\n\n# Save trained models\ntorch.save(generator_without_pono.state_dict(), \"/kaggle/working/sitta_models/generator_without_pono.pth\")\ntorch.save(generator_with_pono.state_dict(), \"/kaggle/working/sitta_models/generator_with_pono.pth\")\n\nprint(\"‚úÖ Models saved successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  9.2: Reload and Test Saved Models","metadata":{}},{"cell_type":"code","source":"# Load trained models for verification\nloaded_gen_without_pono = SITTA_Generator(use_pono=False).cuda()\nloaded_gen_without_pono.load_state_dict(torch.load(\"/kaggle/working/sitta_models/generator_without_pono.pth\"))\n\nloaded_gen_with_pono = SITTA_Generator(use_pono=True).cuda()\nloaded_gen_with_pono.load_state_dict(torch.load(\"/kaggle/working/sitta_models/generator_with_pono.pth\"))\n\nprint(\"‚úÖ Models reloaded successfully!\")\n\n# Generate new images using the reloaded models\ntest_fake_B_without_pono = loaded_gen_without_pono(test_real_A).detach()\ntest_fake_B_with_pono = loaded_gen_with_pono(test_real_A).detach()\n\n# Display reloaded model results\nprint(\"üìä Reloaded Model Results Comparison\")\nvisualize_results(test_real_A, test_fake_B_without_pono)\nvisualize_results(test_real_A, test_fake_B_with_pono)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9.3: Clean Up Files to Save Space","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/dataset  # Remove dataset if not needed anymore\n!rm -rf /kaggle/working/1  # Remove copied repo if needed\nprint(\"‚úÖ Cleaned up unnecessary files!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}